= Caches and artifacts
:toc: macro
:toc-title: Contents

toc::[]

Because jobs run on GitHub-hosted runners start fresh virtual machines on each
run, caching output artifacts and dependencies that do not change between runs
will speed up execution time, and so save on costs.

If you are running self-hosted runners, you can implement your own caching
strategy. There is no requirement on self-hosted runners to always start with
fresh VMs on each run, so you could design your runners to persist things
_by default_.

== Caching

To make your workflows faster and more efficient, you can create and use caches
for dependencies and other commonly reused files.

Workflow runs often reuse the same outputs or downloaded dependencies from one
run to another. Caching package and dependency management can greatly improve
performance.

The following package managers all have dependency caching features:

* npm, Yarn, pnpm (available via `action/setup-node`)
* pip, pipenv, Poetry (`action/setup-python`)
* Gradle, Maven (`action/setup-java`)
* RubyGems (`action/setup-ruby`)
* Go go.sum (`action/setup-go`)

[source,yaml]
----
- uses: ruby/setup-ruby@v1
  with:
    bundler-cache: true
----

[NOTE]
======
The `setup-*` actions do not always cache the folders containing the installed
packages by default. For example, the `setup-node` action will not cache the
`node_modules` folder after an `npm install` command. Therefore, you may need
to use the actions in conjunction with the `actions/cache` action to cache the
dependencies, as documented below.
======

In addition, there's a ready-made action called `actions/cache` that makes it
easy to cache build outputs and other artifacts generated by a workflow.

The `actions/cache` action uses a `key` to identify each unique cache. It also
requires a `path` input, which refers to the file path on the runner where
the caches should be stored.

Example usage:

[source,yaml]
----
steps:
 - uses: actions/cache@v3
   id: cache
   with:
     path: node_modules
     key: ${{ hashFiles('**/package-lock.json') }}
 - name: Install dependencies
   if: steps.cache.outputs.cache-hit != 'true'
   run: npm ci
 - name: Lint & test
   run: |
     npm run lint
     npm run test
----

This workflow has the following caching process:

* Is there a cache matching a hash of the `package-lock.json` file?
  ** YES: Restore the cache and skip the `npm ci` step.
  ** NO: Run `npm ci` to install dependencies; because this will rebuild the
        `node_modules` folder, it will be cached for the next run.
* Execute the lint and test steps.

Another example â€“ this uses an optional input parameter `restore-keys` to
specify alternative keys to caches, all of which will be restored from the path
if the `key` cache is found.

[source,yaml]
----
steps:
  - uses: actions/checkout@v2

  - name: Cache NPM dependencies
    uses: actions/cache@v2
    with:
      path: ~/.npm
      key: ${{ runner.os }}-npm-cache-${{ hashFiles('**/package-lock.json') }}
      restore-keys: |
        ${{ runner.os }}-npm-cache-
----

There are also separate actions for the save and restore cache operations.

Consider the following when using the cache action:

* Be cautious about what you store in the cache. Do not include sensitive
  information like access tokens or login credentials, as anyone with read
  access can access the cache contents.

* Workflow runs can restore caches created in the current branch or the default
  branch (usually `main`). Pull requests can also access caches created in the
  base branch. However, caches cannot be restored across child branches or
  sibling branches.

* The cache action uses a cache key to restore a cache. It is essential to
  understand how cache keys work, including using expressions and restore keys.
  Cache keys should be specific enough to avoid unnecessary cache misses, but
  not too broad as to lead to incorrect hits.

* When a cache key exactly matches an existing cache, it's called a cache hit.
  When there is no exact match, it's a cache miss, and a new cache will be
  automatically created (but only if the job completes successfully).

* GitHub will remove caches that are not accessed for 7 days. Be aware of usage
  limits (see below). If necessary, workflows can be set up to delete specific
  caches.

* GitHub puts a limit on the number of caches you can store, and the total size
  of all caches in a repository. The default limit is 10 GB per repository, but
  this limit may vary depending on your organization's policies or the repository
  administrators' settings.

== Artifacts

When a workflow produces something other than a log entry, the product is called
an _artifact_. For example, a build workflow may produce a Docker container that
can be deployed.

Since each job uses a fresh instance of a virtual machine, by default artifacts
are not preserved between jobs. Therefore, a job that deploys a container cannot,
by default, access the container that was created by the build job.

So preserve artifacts between jobs, the artifacts can be stored. There are a
couple of ready-made actions for this purpose:

* `actions/upload-artifact`
* `actions/download-artifact`

Example usage of `actions/upload-artifact`:

[source,yaml]
----
- name: Archive production artifacts
  uses: actions/upload-artifact@v4
  with:
    name: dist-without-markdown
    path: |
      dist
      !dist/**/*.md
----

Note the following:

* We have to specify a name for the artifact (e.g., `dist-without-markdown`).
* We also have to define the path or files we want to include.
* We can also specify files or directories to exclude.
* Glob patterns can be used to specify both include and exclude collections of files.

You can also set a custom retention period for an artifact using the
`retention-days` option:

[source,yaml]
----
- name: Upload artifact
  uses: actions/upload-artifact@v4
  with:
    name: my-artifact
    path: my_file.txt
    retention-days: 5
----

Once artifacts are downloaded, they can be downloaded by subsequent runs of
the same workflow, or by subsequent jobs in the current workflow run. Here's
an example of a workflow that uploads an artifact in one job and downloads it
in another, dependent job:

[source,yaml]
----
name: Share data between jobs
on: push
jobs:
  # Build job:
  build:
    name: Build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: npm install and build webpack
        run: |
          npm install
          npm run build
      - uses: actions/upload-artifact@main
        with:
          name: webpack artifacts
          path: public/

  # Test job - note the use of `needs` to make sure this job runs after the
  # build job has completed.
  test:
    name: Test
    needs: build
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - uses: actions/download-artifact@main
      with:
        name: webpack artifacts
        path: public
----

Common use cases for artifacts include saving build output, capturing logs for
analysis, and storing test results. Basically: anything you want to access
_later_, either in a subsequent job or workflow run.

Note, at this time it is not possible to share artifacts _between workflows_;
you can't upload an artifact in one workflow and download it from another. This
will require custom logic, but there are actions in the GitHub Actions
Marketplace that implement this feature.

Uploaded artifacts can also be downloaded or deleted via the GitHub GUI or API.

Artifacts are stored in storage space on GitHub. The space is free for public
repositories and some amount is free for private repositories. Either way,
GitHub stores artifacts for 90 days by default. The default retention period can
be customized, and the `actions/upload-artifact` action also provides you with
the option of customizing the retention period of individual artifacts:

[source,yaml]
----
- name: 'Upload Artifact'
  uses: actions/upload-artifact@v2
  with:
    name: my-artifact
    path: my_file.txt
    retention-days: 10
----

== Artifacts vs outputs

Both artifacts and outputs can be used to share data between jobs. Basic outputs
are not well-suited for sharing large amount of data, and cannot be used for
things like capturing the contents of a whole directory, for example. Artifacts
fill this capability gap.

== Artifacts vs caching

Artifacts are:

* Stored for up to 90 days.
* Managed by the `upload-artifact` and `download-artifact` actions.
* Recommended when the stored files are likely to be accessed outside of the
  workflow run, eg. logs, test results, build outputs.

Caches are:

* Stored for up to 7 days.
* Managed via a single action, `cache`.
* Recommended when the stored files are likely to be accessed only within
  the workflow, eg. build dependencies.
